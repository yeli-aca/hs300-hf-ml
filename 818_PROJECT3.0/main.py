# main.py
# å…¥å£ï¼šä¸²èµ·æ¥è·‘ & è¾“å‡ºæŒ‡æ ‡ä¸Žå›¾è¡¨
import os, json, gc
import pandas as pd
import matplotlib.pyplot as plt

from utils import (
    CONFIG, ensure_outdir, load_stock_panel, load_index_5min, load_fundamentals,
    build_features, merge_index_and_target, merge_fundamentals,
    industry_neutralize, add_cross_section_zscores, reduce_mem, safe_cols,
    plot_distribution, plot_corr_heatmap, plot_index_vol,
    compute_ic, plot_ic, quantile_longshort, plot_quantiles, ls_with_cost,
    plot_model_comparison, select_quantile_buckets, estimate_turnover
)
from models import time_split, wf_eval_lasso, run_lasso, run_xgb, run_dnn
from ipca_runner import run_ipca_oos_by_split


def winsorize_series(s, limits=(-5, 5)):
    return s.clip(lower=limits[0], upper=limits[1])


def ensure_code(df: pd.DataFrame, stage: str):
    """ç»Ÿä¸€æ£€æŸ¥ df æ˜¯å¦åŒ…å« code åˆ—"""
    if "code" not in df.columns:
        raise ValueError(f"[{stage}] ç¼ºå°‘ code åˆ—ï¼å®žé™…åˆ—={df.columns.tolist()}")


def main():
    ensure_outdir(CONFIG["OUT_DIR"])

    # ---- æ•°æ® ----
    panel = load_stock_panel(CONFIG["STOCK_DIR"], CONFIG["ROW_SAMPLE_FRAC"])
    idx    = load_index_5min(CONFIG["INDEX_FILE"])
    fund   = load_fundamentals(CONFIG["FUND_FILE"])

    # åŸºæœ¬å¥åº·æ£€æŸ¥
    for obj_name, obj in [("panel", panel), ("idx", idx)]:
        if obj is None or len(obj) == 0:
            raise ValueError(f"{obj_name} ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è¾“å…¥ã€‚")
    ensure_code(panel, "raw panel")

    print("ðŸŸ¢ åŽŸå§‹é¢æ¿ï¼š", len(panel), "rows,", panel["code"].nunique(), "stocks",
          f"range=[{panel['datetime'].min()} ~ {panel['datetime'].max()}]")

    # ---- ç‰¹å¾ä¸Žç›®æ ‡ï¼ˆå…¬å…±åŸºç¡€ï¼‰----
    df_base, factor_cols = build_features(panel)
    del panel; gc.collect()
    ensure_code(df_base, "build_features")

    df_base = merge_index_and_target(df_base, idx)
    ensure_code(df_base, "merge_index_and_target")

    if fund is not None:
        df_base = merge_fundamentals(df_base, fund)
        ensure_code(df_base, "merge_fundamentals")

    # ========== â‘  IPCA ä¸“ç”¨æ”¯è·¯ï¼šä¸åšè¡Œä¸šä¸­æ€§åŒ–ï¼Œä»…åšâ€œæˆªé¢ zscore + winsorâ€ ==========
    df_ipca = df_base[["datetime", "code", "excess_ret_t1"] + factor_cols].copy()
    df_ipca = add_cross_section_zscores(df_ipca, factor_cols)
    use_cols_ipca = [c + "_z" for c in factor_cols if f"{c}_z" in df_ipca.columns]
    if not use_cols_ipca:
        raise ValueError("IPCA use_cols_ipca ä¸ºç©ºï¼Œè¯·æ£€æŸ¥å› å­åˆ—ã€‚")
    for c in use_cols_ipca:
        df_ipca[c] = winsorize_series(df_ipca[c], limits=(-5, 5))
    data_ipca = df_ipca[["datetime", "code", "excess_ret_t1"] + use_cols_ipca]\
                    .dropna(subset=["excess_ret_t1"] + use_cols_ipca)\
                    .copy()

    # ========== â‘¡ ML æ”¯è·¯ï¼ˆLasso/XGB/DNNï¼‰ï¼šè¡Œä¸šä¸­æ€§åŒ– + æˆªé¢ zscore + winsor ==========
    df_ml, eff_cols = industry_neutralize(df_base.copy(), factor_cols, "industry")
    df_ml = add_cross_section_zscores(df_ml, eff_cols)
    use_cols = [c + "_z" for c in eff_cols if f"{c}_z" in df_ml.columns]
    if not use_cols:
        raise ValueError("ML use_cols ä¸ºç©ºï¼Œè¯·æ£€æŸ¥è¡Œä¸šä¸­æ€§åŒ–åŽçš„å› å­åˆ—ã€‚")
    for c in use_cols:
        df_ml[c] = winsorize_series(df_ml[c], limits=(-5, 5))

    expected = ["datetime", "code", "excess_ret_t1"] + use_cols
    data = df_ml[expected].dropna(subset=["excess_ret_t1"] + use_cols).copy()
    ensure_code(data, "data after filter")
    data = reduce_mem(data)

    # ---- ç®€è¦å›¾è¡¨ï¼ˆåŸºäºŽ ML æ”¯è·¯çš„æ•°æ®ï¼‰----
    try: plot_distribution(data["excess_ret_t1"], CONFIG["OUT_DIR"])
    except Exception as e: print("[PLOT] distribution skip:", e)
    try: plot_corr_heatmap(data, use_cols, CONFIG["OUT_DIR"])
    except Exception as e: print("[PLOT] corr_heatmap skip:", e)
    try: plot_index_vol(idx, CONFIG["OUT_DIR"])
    except Exception as e: print("[PLOT] index_vol skip:", e)

    # ---- Walk-forwardï¼ˆå¯é€‰ï¼‰----
    try:
        _ = wf_eval_lasso(data[["datetime", "excess_ret_t1"] + use_cols], use_cols, n_splits=4)
    except Exception as e:
        print("[WF] skip:", e)

    # ---- Train/Testï¼ˆML æ”¯è·¯ï¼‰----
    train, test, cutoff = time_split(data, CONFIG["TEST_RATIO"])
    ensure_code(train, "train"); ensure_code(test, "test")

    Xtr, ytr = train[use_cols], train["excess_ret_t1"]
    Xte, yte = test[use_cols],  test["excess_ret_t1"]

    # ---- ä¸‰æ¨¡åž‹ ----
    res_lasso = run_lasso(Xtr, ytr, Xte, yte, CONFIG["OUT_DIR"])
    res_xgb   = run_xgb  (Xtr, ytr, Xte, yte, CONFIG["OUT_DIR"])
    res_dnn   = run_dnn  (Xtr, ytr, Xte, yte, CONFIG["OUT_DIR"])

    # ---- XGB çš„ IC / åˆ†ä½ / æˆæœ¬æ•æ„Ÿ ----
    base_cols = safe_cols(test, ["datetime", "code", "excess_ret_t1"])
    test_with_score = test[base_cols].copy()
    ensure_code(test_with_score, "test_with_score")
    test_with_score["score"] = res_xgb["y_pred"]

    ic_series, ic_stats = compute_ic(test_with_score, "score", "excess_ret_t1")
    plot_ic(ic_series, CONFIG["OUT_DIR"])

    grp, cum = quantile_longshort(test_with_score, "score", "excess_ret_t1", q=5)
    plot_quantiles(grp, cum, CONFIG["OUT_DIR"])
    try: grp.mean().to_csv(os.path.join(CONFIG["OUT_DIR"], "quantile_mean_returns.csv"))
    except Exception as e: print("[SAVE] quantile_mean_returns skip:", e)

    # æˆæœ¬æ•æ„Ÿï¼ˆå¸¸æ•°æˆæœ¬æ¼”ç¤ºï¼‰
    try:
        ls_net, cum_net = ls_with_cost(grp, est_turnover_bps=0.0002)
        plt.figure(figsize=(9, 4))
        plt.plot(cum_net.index, cum_net.values)
        plt.title("Long-Short (Q5-Q1) Cumulative Return with Cost (2 bps)")
        plt.tight_layout()
        plt.savefig(os.path.join(CONFIG["OUT_DIR"], "fig_ls_cum_with_cost.png"), dpi=300)
        plt.close()
    except Exception as e:
        print("[PLOT] ls_with_cost skip:", e)

    # åŠ¨æ€æ¢æ‰‹æˆæœ¬ï¼ˆåŸºäºŽæŒä»“å˜åŠ¨ï¼‰
    try:
        buckets = select_quantile_buckets(test_with_score, "score", q=5)
        turns   = estimate_turnover(buckets)   # index: datetime, cols: Q1..Q5
        cost_one_way = 0.0008  # 8 bps å•è¾¹
        ls_net_dyn   = grp["LS"] - (turns["Q5"] + turns["Q1"]) * cost_one_way
        cum_net_dyn  = (1 + ls_net_dyn).cumprod() - 1
        plt.figure(figsize=(9,4))
        plt.plot(cum_net_dyn.index, cum_net_dyn.values)
        plt.title("Long-Short (Q5-Q1) Cumulative Return â€” turnover-cost")
        plt.tight_layout()
        plt.savefig(os.path.join(CONFIG["OUT_DIR"], "fig_ls_cum_with_turnover_cost.png"), dpi=300)
        plt.close()
        turns.to_csv(os.path.join(CONFIG["OUT_DIR"], "turnover_by_quantile.csv"))
        ls_net_dyn.rename("LS_net_turnover_cost").to_csv(
            os.path.join(CONFIG["OUT_DIR"], "ls_net_turnover_cost.csv")
        )
    except Exception as e:
        print("[TURNOVER] skip:", e)

    # ---- IPCA OOSï¼šé€‰æœ€ä¼˜å› å­æ•°ï¼ˆç‹¬ç«‹äºŽ ML æ”¯è·¯ï¼‰----
    train_ipca, test_ipca, _ = time_split(data_ipca, CONFIG["TEST_RATIO"])
    best_ipca, best_r2 = None, -1e9
    for k in [3, 5, 10]:
        try:
            res_ipca = run_ipca_oos_by_split(train_ipca, test_ipca, use_cols_ipca, CONFIG["OUT_DIR"], n_factors=k)
            if res_ipca["r2"] > best_r2:
                best_ipca, best_r2 = res_ipca, res_ipca["r2"]
        except Exception as e:
            print(f"[IPCA] n_factors={k} failed:", e)
    if best_ipca is None:
        raise RuntimeError("IPCA å…¨éƒ¨é…ç½®å¤±è´¥")

    print(f"[IPCA] best result with n_factors={best_ipca['model'].n_factors}, R2={best_ipca['r2']:.6f}")
    print("[INFO] IPCA Gamma, Factors, and prediction files saved to:", CONFIG["OUT_DIR"])

    # ---- æ±‡æ€»å¹¶å‡ºå›¾ ----
    summary = {
        "lasso":  {"R2": float(res_lasso["r2"]), "MSE": float(res_lasso["mse"])},
        "xgboost":{"R2": float(res_xgb["r2"]),   "MSE": float(res_xgb["mse"])},
        "dnn":    {"R2": float(res_dnn["r2"]),   "MSE": float(res_dnn["mse"])},
        "ipca":   {"R2": float(best_ipca["r2"]), "MSE": float(best_ipca.get("mse", float('nan')))},
        "cutoff": str(cutoff),
        "n_train": int(len(train)),
        "n_test":  int(len(test)),
        "n_codes": int(data["code"].nunique())
    }
    with open(os.path.join(CONFIG["OUT_DIR"], "metrics_summary.json"), "w", encoding="utf-8") as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)

    print("\n===== Summary =====")
    print(json.dumps(summary, indent=2, ensure_ascii=False))
    print(f"[INFO] All results saved under: {CONFIG['OUT_DIR']}")

    plot_model_comparison(
        summary_json_path=os.path.join(CONFIG["OUT_DIR"], "metrics_summary.json"),
        out_dir=CONFIG["OUT_DIR"]
    )


if __name__ == "__main__":
    print(">>> starting main() ...")
    try:
        main()
    except Exception as e:
        print("[ERROR] main failed:", e)
    finally:
        print(">>> finished main()")
